{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lzp8kOckHlv",
        "outputId": "971e092a-fb54-4bce-e91a-444b3f810757"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.1/142.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.6/663.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -U -q google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "78KZe1qLjnkU"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "APIKEY = \"AIzaSyAXxUj2bE3FXnWy4OegQUXibwCAKVhSvXA\"\n",
        "genai.configure(api_key=APIKEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WrSQ8YLLkaCu"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('models/gemini-1.5-pro-latest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "rub5Fp7YkcKU",
        "outputId": "0642bd0e-37b3-4282-fdbe-48797d6c26bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! How can I help you today? 😊 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = model.generate_content(\"Hello Gemini!\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpSzPeIVnEU0"
      },
      "outputs": [],
      "source": [
        "#prompt = \"Please complete the following response to the audio after '...' and do not include '...' in your response: Hello my ...\"\n",
        "#response = model.generate_content([prompt, your_file], stream=True)\n",
        "#for chunk in response:\n",
        "  #print(chunk.text)\n",
        "#print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8QHrot4AoJj-"
      },
      "outputs": [],
      "source": [
        "#multiturn testing\n",
        "import os\n",
        "file_array = []\n",
        "root = '/content'\n",
        "for file in os.listdir(root):\n",
        "  if file.endswith('.wav'):\n",
        "    file_path = os.path.join(root, file)\n",
        "    print(file_path)\n",
        "    new_up = genai.upload_file(path=file_path)\n",
        "    prompt_final = \"Respond appropriately to the given context.\"\n",
        "    response_final = model.generate_content([new_up, prompt_final], stream = True)\n",
        "    for chunk in response_final:\n",
        "      print(chunk.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1oTxkh1SvUn8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "def copilot(user_input, input_path):\n",
        "  new_up = genai.upload_file(path=input_path)\n",
        "  prompt_final = f\"Finish the following after '...': {user_input}...\"\n",
        "  response_final = model.generate_content([new_up, prompt_final])\n",
        "  result_string = (response_final.text).replace(f'...{user_input}', \"\")\n",
        "  result_string = (response_final.text).replace(f'... {user_input}', \"\")\n",
        "  #result_string = re.sub(r'\\.{3}', '', result_string)\n",
        "  print(result_string)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "d4BFl9M_1WXb",
        "outputId": "53a1c27d-c035-42fc-b241-0f0674d79c5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " move on and discuss something else.  Is there anything specific you'd like to talk about? \n",
            "\n",
            " you even talking about? \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#testing lol\n",
        "input_1 = \"I agree! Let's\"\n",
        "copilot(input_1, '/content/sample_turn2.wav')\n",
        "\n",
        "input_2 = \"What on god's name are\"\n",
        "copilot(input_2, '/content/sample_turn2.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "zyQagZpH6hz8",
        "outputId": "69dd7642-5752-47f2-a805-906162dba096"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-82900c1d5ba4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"I wish you shame on your family and\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcopilot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/sample_turn2.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-e3617b2413e4>\u001b[0m in \u001b[0;36mcopilot\u001b[0;34m(user_input, input_path)\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mprompt_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Finish the following after '...': {user_input}...\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mresponse_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_up\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt_final\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mresult_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresponse_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'...{user_input}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mresult_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresponse_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'... {user_input}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;31m#result_string = re.sub(r'\\.{3}', '', result_string)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/types/generation_types.py\u001b[0m in \u001b[0;36mtext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    348\u001b[0m                 \u001b[0;34m\"The `response.text` quick accessor only works when the response contains a valid \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0;34m\"`Part`, but none was returned. Check the `candidate.safety_ratings` to see if the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The `response.text` quick accessor only works when the response contains a valid `Part`, but none was returned. Check the `candidate.safety_ratings` to see if the response was blocked."
          ]
        }
      ],
      "source": [
        "input_3 = \"I wish you shame on your family and\"\n",
        "copilot(input_3, '/content/sample_turn2.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNVvqitR-bPX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12 (main, Jul 10 2023, 17:08:18) [Clang 14.0.0 (clang-1400.0.29.202)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "d598c33b522e25cafce36b25ed94febb600403afcb0cdb3306084ede8c047345"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
